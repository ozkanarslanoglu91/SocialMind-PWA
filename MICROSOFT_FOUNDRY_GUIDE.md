# Microsoft Foundry & Azure OpenAI Entegrasyonu

## ğŸ¯ Genel BakÄ±ÅŸ

SocialMind projesi, Microsoft'un AI ekosistemiyle entegre edilmiÅŸtir:

- **Microsoft Foundry**: Phi serisi modeller ve hosted open-source modeller (Llama, Mistral)
- **Azure OpenAI**: Enterprise Ã¶zellikleriyle OpenAI modelleri (compliance, SLA, private endpoints)

## ğŸ“¦ Dahil Edilen Modeller

### Microsoft Foundry Modelleri

1. **Phi-4** (16K context, ÃœCRETSÄ°Z)
   - Microsoft'un en son kÃ¼Ã§Ã¼k dil modeli
   - HÄ±zlÄ± ve edge cihazlar iÃ§in optimize

2. **Phi-3.5 Mini** (128K context, ÃœCRETSÄ°Z)
   - GeniÅŸ context window
   - Mobil ve edge deployment iÃ§in ideal

3. **Phi-3 Medium** (128K context, ÃœCRETSÄ°Z)
   - Dengeli performans
   - Orta Ã¶lÃ§ekli uygulamalar iÃ§in

4. **Llama 3.3 70B Instruct** ($0.77/1M token)
   - Meta'nÄ±n gÃ¼Ã§lÃ¼ modeli Azure'da host edilmiÅŸ
   - KarmaÅŸÄ±k gÃ¶revler iÃ§in

5. **Mistral Large 2411** ($2.00/1M token)
   - En geliÅŸmiÅŸ Mistral modeli
   - Profesyonel iÃ§erik Ã¼retimi

6. **Mistral Small** ($0.20/1M token)
   - HÄ±zlÄ± ve uygun maliyetli
   - Basit iÃ§erik gÃ¶revleri iÃ§in

### Azure OpenAI Modelleri

1. **GPT-4o Azure** ($2.50/1M token)
   - Enterprise compliance
   - GeliÅŸmiÅŸ reasoning ve multimodal

2. **GPT-4 Turbo Azure** ($10.00/1M token)
   - YÃ¼ksek throughput
   - 128K context window

3. **GPT-3.5 Turbo Azure** ($0.50/1M token)
   - HÄ±zlÄ± ve ekonomik
   - Basit gÃ¶revler iÃ§in

## ğŸ”§ Kurulum

### 1. API AnahtarlarÄ±

#### Microsoft Foundry

1. [GitHub Models](https://github.com/marketplace/models) Ã¼zerinden Ã¼cretsiz eriÅŸim
2. API anahtarÄ±nÄ±zÄ± kopyalayÄ±n
3. `appsettings.json` iÃ§inde gÃ¼ncelleyin:

```json
"AIProviders": {
  "MicrosoftFoundry": {
    "ApiKey": "YOUR_GITHUB_TOKEN",
    "BaseUrl": "https://models.inference.ai.azure.com",
    "DefaultModel": "phi-4"
  }
}
```

#### Azure OpenAI

1. [Azure Portal](https://portal.azure.com) Ã¼zerinden Azure OpenAI kaynaÄŸÄ± oluÅŸturun
2. Model deployment yapÄ±n (Ã¶rn: gpt-4o)
3. Endpoint ve API key'i alÄ±n
4. `appsettings.json` iÃ§inde gÃ¼ncelleyin:

```json
"AIProviders": {
  "AzureOpenAI": {
    "ApiKey": "YOUR_AZURE_OPENAI_KEY",
    "Endpoint": "https://YOUR-RESOURCE.openai.azure.com",
    "DeploymentName": "gpt-4o",
    "ApiVersion": "2024-02-15-preview"
  }
}
```

### 2. Service SeÃ§imi

`Program.cs` iÃ§inde hangi AI servisini kullanacaÄŸÄ±nÄ±zÄ± seÃ§in:

```csharp
// Mock servis kullanÄ±mÄ± (Development)
var enableMockServices = builder.Configuration.GetValue<bool>("AppSettings:EnableMockServices", true);

if (enableMockServices)
{
    builder.Services.AddScoped<IAIService, MockAIService>();
}
else
{
    // Production iÃ§in gerÃ§ek servis
    builder.Services.AddScoped<IAIService, MicrosoftFoundryAIService>();
    // Ya da
    builder.Services.AddScoped<IAIService, AzureOpenAIService>();
}
```

### 3. Named Service Pattern (Ä°steÄŸe BaÄŸlÄ±)

Birden fazla AI provider'Ä± dinamik olarak kullanmak iÃ§in:

```csharp
// Program.cs iÃ§inde
builder.Services.AddKeyedScoped<IAIService, MicrosoftFoundryAIService>("MicrosoftFoundry");
builder.Services.AddKeyedScoped<IAIService, AzureOpenAIService>("AzureOpenAI");

// Component iÃ§inde kullanÄ±m
@inject IServiceProvider ServiceProvider

private async Task GenerateWithProvider(string provider)
{
    var aiService = ServiceProvider.GetKeyedService<IAIService>(provider);
    var content = await aiService.GenerateContentAsync(prompt, modelId);
}
```

## ğŸš€ KullanÄ±m

### Basit Ä°Ã§erik OluÅŸturma

```csharp
@inject IAIService AIService

private async Task GenerateContent()
{
    var content = await AIService.GenerateContentAsync(
        prompt: "Yapay zeka hakkÄ±nda ilgi Ã§ekici bir tweet yaz",
        modelId: "phi-4",
        language: "tr"
    );

    Console.WriteLine(content.Content);
    Console.WriteLine($"KullanÄ±lan token: {content.Metadata["tokensUsed"]}");
}
```

### Ã‡oklu Varyant OluÅŸturma

```csharp
var contents = await AIService.GenerateMultipleContentAsync(
    prompt: "LinkedIn iÃ§in bir post yaz",
    modelId: "mistral-large-2411",
    count: 3
);

foreach (var content in contents)
{
    Console.WriteLine($"Varyant {contents.IndexOf(content) + 1}: {content.Content}");
}
```

### Platform Optimizasyonu

```csharp
var optimized = await AIService.OptimizeContentAsync(
    content: "Uzun bir iÃ§erik metni...",
    platform: SocialPlatform.Twitter,
    modelId: "phi-4"
);

Console.WriteLine($"Twitter iÃ§in optimize edildi: {optimized}");
```

### Hashtag OluÅŸturma

```csharp
var hashtags = await AIService.GenerateHashtagsAsync(
    content: "Yapay zeka sosyal medya yÃ¶netimini kolaylaÅŸtÄ±rÄ±yor",
    platform: SocialPlatform.Instagram,
    count: 10
);

Console.WriteLine($"Ã–nerilen hashtagler: #{string.Join(" #", hashtags)}");
```

## ğŸ’° Maliyet KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Model                   | Fiyat (1M token) | KullanÄ±m Senaryosu                    |
| ----------------------- | ---------------- | ------------------------------------- |
| **Phi-4**               | ÃœCRETSÄ°Z         | Test, development, prototipleme       |
| **Phi-3.5 Mini**        | ÃœCRETSÄ°Z         | Mobil uygulamalar, edge computing     |
| **Mistral Small**       | $0.20            | Basit iÃ§erik Ã¼retimi, gÃ¼nlÃ¼k gÃ¶revler |
| **GPT-3.5 Turbo Azure** | $0.50            | HÄ±zlÄ± yanÄ±tlar, basit iÃ§erikler       |
| **Llama 3.3 70B**       | $0.77            | KarmaÅŸÄ±k iÃ§erikler, Ã¶zel gÃ¶revler     |
| **Mistral Large**       | $2.00            | Profesyonel iÃ§erik, yÃ¼ksek kalite     |
| **GPT-4o Azure**        | $2.50            | Enterprise uygulamalar, compliance    |
| **GPT-4 Turbo Azure**   | $10.00           | YÃ¼ksek throughput, kritik iÅŸlemler    |

## ğŸ¢ Enterprise Ã–zellikler (Azure OpenAI)

1. **Compliance ve Sertifikalar**
   - SOC 2, ISO 27001, HIPAA, GDPR uyumlu
   - Avrupa veri yerleÅŸimi seÃ§eneÄŸi

2. **GÃ¼venlik**
   - Private endpoints (VNet entegrasyonu)
   - Azure Active Directory authentication
   - Managed identities

3. **SLA ve Destek**
   - %99.9 uptime garantisi
   - 7/24 Microsoft desteÄŸi
   - Premium support seÃ§enekleri

4. **YÃ¶netim**
   - Azure Monitor entegrasyonu
   - Cost management ve budget alerts
   - Usage analytics ve reporting

## ğŸ” Model SeÃ§im Rehberi

### GeliÅŸtirme ve Test

- **Ã–neri**: Phi-4 veya Phi-3.5 Mini (Ã¼cretsiz)
- **Neden**: SÄ±nÄ±rsÄ±z kullanÄ±m, hÄ±zlÄ± iterasyon

### Startup/KÃ¼Ã§Ã¼k Proje

- **Ã–neri**: Mistral Small veya GPT-3.5 Turbo Azure
- **Neden**: DÃ¼ÅŸÃ¼k maliyet, yeterli performans

### Orta Ã–lÃ§ekli Proje

- **Ã–neri**: Llama 3.3 70B veya Mistral Large
- **Neden**: Kalite-maliyet dengesi

### Enterprise/Kurumsal

- **Ã–neri**: GPT-4o Azure veya GPT-4 Turbo Azure
- **Neden**: Compliance, SLA, Ã¶zel destek

## ğŸ› ï¸ Troubleshooting

### API Key HatasÄ±

```
Error: 401 Unauthorized
```

**Ã‡Ã¶zÃ¼m**: `appsettings.json` iÃ§inde API key'inizi kontrol edin

### Rate Limit HatasÄ±

```
Error: 429 Too Many Requests
```

**Ã‡Ã¶zÃ¼m**: Ä°stekler arasÄ±na `await Task.Delay(1000)` ekleyin

### Timeout HatasÄ±

```
Error: Request timeout
```

**Ã‡Ã¶zÃ¼m**: `HttpClient.Timeout` deÄŸerini artÄ±rÄ±n (Program.cs)

### Model BulunamadÄ± HatasÄ±

```
Error: Model not found
```

**Ã‡Ã¶zÃ¼m**: Azure OpenAI'da deployment oluÅŸturulduÄŸunu doÄŸrulayÄ±n

## ğŸ“š Kaynaklar

- [Microsoft Foundry Documentation](https://github.com/marketplace/models)
- [Azure OpenAI Service Documentation](https://learn.microsoft.com/azure/ai-services/openai/)
- [Phi Models Overview](https://azure.microsoft.com/blog/introducing-phi-4-microsoft-most-capable-ai-models/)
- [Azure AI Pricing](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/)

## ğŸ”„ Sonraki AdÄ±mlar

1. âœ… Model registry'ye Foundry modelleri eklendi
2. âœ… Service implementasyonlarÄ± oluÅŸturuldu
3. âœ… Configuration yapÄ±landÄ±rÄ±ldÄ±
4. â³ API anahtarlarÄ±nÄ± appsettings.json'a ekleyin
5. â³ Mock moddan real mode'a geÃ§iÅŸ yapÄ±n
6. â³ Usage tracking ve cost monitoring ekleyin
7. â³ Caching mekanizmasÄ± ekleyin (maliyeti dÃ¼ÅŸÃ¼rmek iÃ§in)

## ğŸ’¡ Ä°puÃ§larÄ±

1. **Development**: Mock servis kullanÄ±n, gerÃ§ek API Ã§aÄŸrÄ±larÄ± yapmayÄ±n
2. **Testing**: Phi-4 kullanÄ±n (Ã¼cretsiz)
3. **Production**: KullanÄ±m senaryonuza gÃ¶re model seÃ§in
4. **Caching**: AynÄ± promptlar iÃ§in cache kullanÄ±n
5. **Monitoring**: Token kullanÄ±mÄ±nÄ± takip edin
6. **Fallback**: Birincil provider baÅŸarÄ±sÄ±z olursa fallback provider kullanÄ±n
